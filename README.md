# ðŸ˜ï¸ XÃ¢y dá»±ng pineline dá»¯ liá»‡u nhÃ  Ä‘áº¥t phá»¥c vá»¥ dá»± Ä‘oÃ¡n giÃ¡ nhÃ 

## ðŸ“Œ Project Overview 

Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng quy trÃ¬nh Ká»¹ thuáº­t dá»¯ liá»‡u tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i cho dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n Ä‘á»ƒ há»— trá»£ dá»± Ä‘oÃ¡n giÃ¡ nhÃ .

Quy trÃ¬nh thu tháº­p dá»¯ liá»‡u nhÃ  á»Ÿ thÃ´ tá»« cÃ¡c trang web báº¥t Ä‘á»™ng sáº£n, xá»­ lÃ½ vÃ  lÆ°u trá»¯ dá»¯ liá»‡u Ä‘Ã³ á»Ÿ Ä‘á»‹nh dáº¡ng cÃ³ cáº¥u trÃºc, Ä‘á»“ng thá»i chuáº©n bá»‹ dá»¯ liá»‡u cho cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y.

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ dÃ nh cho nhá»¯ng ngÆ°á»i má»›i báº¯t Ä‘áº§u Ká»¹ thuáº­t dá»¯ liá»‡u muá»‘n thá»±c hÃ nh lÃ m viá»‡c vá»›i dá»¯ liá»‡u trong tháº¿ giá»›i thá»±c vÃ  hiá»ƒu cÃ¡ch cÃ¡c Ä‘Æ°á»ng dáº«n dá»¯ liá»‡u há»— trá»£ phÃ¢n tÃ­ch dá»± Ä‘oÃ¡n.

---- 

## ðŸŽ¯ Project Objectives 

* Thu tháº­p dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n tá»« cÃ¡c nguá»“n trá»±c tuyáº¿n.
* LÃ m sáº¡ch vÃ  xá»­ lÃ½ dá»¯ liá»‡u thÃ´ , khÃ´ng cÃ³ cáº¥u trÃºc.
* LÆ°u trá»¯ dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.
* Chuáº©n bá»‹ Ä‘áº·c trÆ°ng cho cÃ¡c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n giÃ¡ nhÃ .
* XÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh phá»¥c vá»¥ bÃ i tÃ³a dá»± Ä‘oÃ¡n giÃ¡.
* xÃ¢y dá»±ng giao diá»‡n demo 

----

## ðŸŒ Data source 

+) crawl dá»¯ liá»‡u tá»« trang web batdongsan.com.

----

## ðŸ§± Pineline Overview 

```
Web / API 
-> Ingest (Python)
-> Raw Data (CSV / JSON / raw tables)
-> Clean & Normalize (python)
-> Data warehouse (Postgres)

-> dbt (Analytics layer)
   â”œâ”€â”€ fact_listings
   â”œâ”€â”€ dim_location
   â”œâ”€â”€ dim_time
   â””â”€â”€ fact_price_history

â†’ Feature Engineering (Python)
   â”œâ”€â”€ encode
   â”œâ”€â”€ scale
   â”œâ”€â”€ aggregate
   â””â”€â”€ feature store / dataset_ml

â†’ Train ML Model
â†’ Prediction / Evaluation
```

---

## ðŸ”„ Data Pipeline Architecture

The pipeline includes the following stages:

1. **Data Ingestion**

   * Crawl house listing data using Selenium & BeautifulSoup
   * Extract attributes such as:

     * Location
     * Area (mÂ²)
     * Number of bedrooms
     * Price
     * Property type

2. **Data Cleaning & Validation**

   * Remove duplicate listings
   * Handle missing or invalid values
   * Standardize price and area units

3. **Data Storage**

   * Store cleaned data in CSV files and SQLite database
   * Ensure data consistency for further analysis

4. **Feature Engineering**

   * Encode categorical variables (One-Hot Encoding)
   * Normalize numerical features
   * Generate feature vectors for ML models

5. **Data Serving for ML**

   * Export final dataset for training and evaluation
   * Support house price prediction models

---

## ðŸ›  Tech Stack

* **Programming Language:** Python
* **Web Scraping:** Selenium, BeautifulSoup
* **Data Processing:** Pandas, NumPy
* **Database:** SQLite
* **Machine Learning:** Scikit-learn
* **Visualization:** Matplotlib

---

## ðŸ“‚ Project Structure

```
real-estate-data-pipeline/
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Raw crawled data
â”‚   â”œâ”€â”€ cleaned/           # Cleaned datasets
â”‚
â”‚â”€â”€ ingestion/
â”‚   â”œâ”€â”€ crawl_real_estate.py
â”‚
â”‚â”€â”€ processing/
â”‚   â”œâ”€â”€ clean_data.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚
â”‚â”€â”€ storage/
â”‚   â”œâ”€â”€ database.db
â”‚
â”‚â”€â”€ model/
â”‚   â”œâ”€â”€ train_model.py
â”‚
â”‚â”€â”€ main.py                # Run full pipeline
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
```



